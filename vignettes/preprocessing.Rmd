---
title: "Preprocessing with `CATALYST`"
date: "`r BiocStyle::doc_date()`"
author:
- name: Helena L Crowell
  email: helena.crowell@uzh.ch
  affiliation:
  - &IMLS Institute for Molecular Life Sciences, University of Zurich, Switzerland
  - &SIB SIB Swiss Institute of Bioinformatics, University of Zurich, Switzerland
- name: Vito RT Zanotelli
  affiliation:
  - &DQBM Department of Quantitative Biomedicine, University of Zurich, Switzerland
- name: StÃ©phane Chevrier
  affiliation:
  - *DQBM
- name: Bernd Bodenmiller
  affiliation:
  - *DQBM
- name: Mark D Robinson
  affiliation:
  - *IMLS
  - *SIB
package: "`r BiocStyle::pkg_ver('CATALYST')`"
abstract: >
    By addressing the limit of measurable fluorescent parameters due to instrumentation and spectral overlap, mass cytometry (CyTOF) combines heavy metal spectrometry to allow examination of up to (theoretically) 100 parameters at the single cell level. While spectral overlap is significantly less pronounced in CyTOF than flow cytometry, spillover due to detection sensitivity, isotopic impurities, and oxide formation can impede data interpretability. We designed `r Biocpkg("CATALYST")` (Cytometry dATa anALYSis Tools) to provide tools for (pre)processing and analysis of cytometry data, including compensation and in particular, an improved implementation of the single-cell deconvolution algorithm.
bibliography: "`r file.path(system.file('extdata', package = 'CATALYST'), 'refs.bib')`"
csl: science.csl
vignette: >
  %\VignetteIndexEntry{"1. Preprocessing"}
  %\VignettePackage{CATALYST}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
output: 
  BiocStyle::html_document
---
\DeclareMathOperator*{\argmin}{argmin}

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

```{r warning = FALSE, message = FALSE}
# load required packages
library(CATALYST)
library(cowplot)
library(flowCore)
library(ggplot2)
library(SingleCellExperiment)
```

# Data examples

- **Normalization:**  
`raw_data` is a `flowSet` with 2 experiments, each containing 2'500 raw measurements with a variation of signal over time. Samples were mixed with DVS beads captured by mass channels 140, 151, 153, 165 and 175.
- **Debarocoding:**  
To demonstrate the debarcoding workflow with `r Biocpkg("CATALYST")`, we provide `sample_ff` which follows a 6-choose-3 barcoding scheme where mass channels 102, 104, 105, 106, 108, and 110 were used for labeling such that each of the 20 individual barcodes are positive for exactly 3 out of the 6 barcode channels. Accompanying this, `sample_key` contains a binary code of length 6 for each sample, e.g. 111000, as its unique identifier.
- **Compensation:**  
Alongside the multiplexed-stained cell sample `mp_cells`, the package contains 36 single-antibody stained controls in `ss_exp` where beads were stained with antibodies captured by mass channels 139, 141 through 156, and 158 through 176, respectively, and pooled together. Note that, to decrease running time, we downsampled to a total of 10'000 events. Lastly, `isotope_list` contains a named list of isotopic compositions for all elements within 75 through 209 u corresponding to the CyTOF mass range at the time of writing [@isotopes].

# Data organization

Data used and retuned throughout preprocessing are organized into an object of the `r Biocpkg("SingleCellExperiment")` (SCE) class. A SCE can be constructed from a single or set of FCS files, `flowFrame`(s) or `flowSet` (from the `r Biocpkg("flowCore")` package) using `CATALYST`'s `fcs2sce` function. 

`fcs2sce` will automatically identify channels not corresponding to masses (e.g., event times), remove them from the output SCE's assay data, and store them as internal event metadata (`int_colData`).

When multiple files or frames are supplied, `fcs2sce` will concatenate the data into a single object, and argument `by_time` (default `TRUE`) specifies whether runs should be ordered by their acquisition time (`keyword(x, "$BTIM")`, where `x` is a `flowFrame` or `flowSet`). 

Optionally, a `"file_no"` column can be added to the output SCE's `colData` to track which file/frame events originally source from.

Finally, when `transform` (default `TRUE`), an arcsinh-transformation with cofactor `cofactor` (defaults to 5) is applied to the input (count) data, and the resulting expression matrix is stored in the `"exprs"` assay slot of the output SCE.

```{r fcs2sce}
data(raw_data)
(sce <- fcs2sce(x = raw_data, file_no = TRUE))
# view number of events per sample
table(int_colData(sce)$file_no)
# view non-mass channels
names(int_colData(sce))
```

# Gating & visualization

`gateCytof` currently supports the following `type`s of gates:

- `rect`: Rectangular gate with boundaries specified via `xy = list(c(xmin, ymin), c(xmax, ymax))`.
- `elip`: Eliptical gate with the upper quantile to be removed specified via `q`, the number of cluster centers specified via `k`, and the target cluster center specified via `xy = c(x, y)`; if `k = NULL`, `gateCytof` will estimate the number of clusters via maximizing the average Silhouette information for $k\in[2,5]$.
- `live`: Live-gate with the upper quantile to be removed specified via `q`, and line parameters specified via `bs = c(intercept, slope)`.

```{r gateCytof-beads, fig.small = TRUE}
sce <- gateCytof(sce, 
    chs = c("Ir191Di", "Ho165Di"),
    gate_id = "beads",
    type = "rect", 
    xy = list(c(0, 6), c(2, 8)))
plotScatter(sce, gate_id = "beads")
```

We can easily compute the fraction of cells selected by the above gate:

```{r results = "hold"}
# view number & fraction selected cells
table(sce$beads)
mean(sce$beads)
```

By default, `gateCytof` will gate on all cells. Alternatively, a previously applied gate my be specified via `gate_on` from which to subset cells from prior to gating. In this case, the newly created gate's parent will be stored in `int_metadata(x)$gates$<gate_id>`.

```{r message = FALSE, fig.width = 5}
# apply rectangular gate
chs <- c("Tb159Di", "Yb176Di")
sce <- gateCytof(sce, chs, gate_id = "gate1",
    type = "rect", xy = list(c(0, 4), c(6, 8)))

# gate on cells selected by 'gate1'
sce <- gateCytof(sce, chs, gate_id = "gate2",
    type = "rect", xy = list(c(2, 4), c(4, 8)),
    gate_on = "gate1") 

# visualize gating sequence
plot_grid(plotlist = lapply(c("gate1", "gate2"), function(g) 
    plotScatter(sce, gate_id = g, color_by = "selection")))
```

Finally, a grouping variable may be specified via `group_by` such that the gate will be applied separately to different subsets of cells.

```{r gateCytof-cells, fig.width = 2.5}
sce <- gateCytof(sce,
    chs = c("Ir191Di", "Ir193Di"),
    gate_id = "cells", 
    type = "elip", 
    xy = c(4, 4))
```

By default, bins will be colored by density. When a `gate_id` has been supplied, `color_by = "selection"` will instead color cells by whether or not they have been selected such that non-gated cells will be greyed out.

Finally, we can apply a sample-specific gating strategy via using `group_by = "file_name"`:

```{r gateCytof-cells2, fig.width = 5}
sce <- gateCytof(sce, 
    chs = c("Ir191Di", "Ir193Di"),
    gate_id = "cells2",
    group_by = "file_name",
    type = "elip", 
    xy = c(4, 4))
plotScatter(sce, gate_id = "cells2")
```

## Gating for live cells

# Normalization

`r Biocpkg("CATALYST")` provides an implementation of bead-based normalization as described by Finck et al. [@Finck13]. Here, identification of bead-singlets (used for normalization), as well as of bead-bead and cell-bead doublets (to be removed) is automated as follows: 

1. beads are identified as events with their top signals in the bead channels
1. cell-bead doublets are remove by applying a separation cutoff to the distance between the lowest bead and highest non-bead signal
1. events passing all vertical gates defined by the lower bounds of bead signals are removed (these include bead-bead and bead-cell doublets)
1. bead-bead doublets are removed by applying a default $median\;\pm5\;mad$ rule to events identified in step 2. The remaining bead events are used for normalization.

## Normalization workflow

### `normCytof`: Normalization using bead standards

Since bead gating is automated here, normalization comes down to a single function that takes a `SingleCellExperiment` as input and only requires specification of the `beads` to be used for normalization. Valid options are:

- `"dvs"` for bead masses 140, 151, 153, 165, 175
- `"beta"` for bead masses 139, 141, 159, 169, 175
- or a custom numeric vector of bead masses

By default, we apply a $median\;\pm5\;mad$ rule to remove low- and high-signal events from the bead population used for estimating normalization factors. The extent to which bead populations are trimmed can be adjusted via `trim`. The population will become increasingly narrow and bead-bead doublets will be exluded as the `trim` value decreases. Notably, slight *over-trimming* will **not** affect normalization. It is therefore recommended to choose a `trim` value that is small enough to assure removal of doublets at the cost of a small bead population to normalize to.

`normCytof` will return the following list of SCE(s)...

- `data`: Input dataset including normalized intensities as assay slot `"normed"`.
    - if `remove_beads = FALSE`, `colData` columns `"is_bead"` and `"remove"` indicate whether an event has been marker as a bead or for removal, respectively.
    - otherwise, bead and doublet events are excluded and the following additional data is returned:
        - `beads`: Subset of identified bead events.
        - `removed`: Subset of all cells that have been from the original dataset,
including bead events as well as bead-bead and bead-cell doublets.

...and `ggplot`-objects:

- `scatter`: Scatter plot of bead vs. DNA intensities with indication of applied gates.
- `lines`: Running-median smoothed bead intensities vs. time before and after normalization.

```{r normCytof, fig.width = 8, fig.height = 6}
sce <- fcs2sce(raw_data)
res <- normCytof(sce, beads = "dvs", k = 50, verbose = FALSE)
# check number & percentage of bead / removed events
n <- ncol(sce); ns <- c(ncol(res$beads), ncol(res$removed))
data.frame(
    check.names = FALSE, 
    "#" = c(ns[1], ns[2]), 
    "%" = 100*c(ns[1]/n, ns[2]/n),
    row.names = c("beads", "removed"))
# extract data excluding beads & doubltes,
# and including normalized intensitied
sce <- res$data
sum(sce$is_bead) == 0
```

```{r normCytof-scatter, fig.wide = TRUE, fig.width = 10, fig.height = 2}
# plot bead vs. dna scatters
res$scatter
```

```{r normCytof-lines, fig.wide = TRUE, fig.width = 8, fig.height = 4}
# plot smoothed bead intensities
res$lines
```

# Debarcoding

`r BiocStyle::Biocpkg("CATALYST")` provides an implementation of the single-cell deconvolution algorithm described by Zunder et al. [@Zunder15]. The package contains three functions for debarcoding and three visualizations that guide selection of thresholds and give a sense of barcode assignment quality.

In summary, events are assigned to a sample when i) their positive and negative barcode populations are separated by a distance larger than a threshold value and ii) the combination of their positive barcode channels appears in the barcoding scheme. Depending on the supplied scheme, there are two possible ways of arriving at preliminary event assignments:

1. **Doublet-filtering**:  
Given a binary barcoding scheme with a coherent number $k$ of positive channels for all IDs, the $k$ highest channels are considered positive and $n-k$ channels negative. Separation of positive and negative events equates to the difference between the $k$th highest and $(n-k)$th lowest intensity value. If a numeric vector of masses is supplied, the barcoding scheme will be an identity matrix; the most intense channel is considered positive and its respective mass assigned as ID.   
1. **Non-constant number of 1's**:  
Given a non-uniform number of 1's in the binary codes, the highest separation between consecutive barcodes is looked at. In both, the doublet-filtering and the latter case, each event is assigned a binary code that, if matched with a code in the barcoding scheme supplied, dictates which row name will be assigned as ID. Cells whose positive barcodes are still very low or whose binary pattern of positive and negative barcodes doesn't occur in the barcoding scheme will be given ID 0 for *"unassigned"*.

All data required for debarcoding are held in objects of the `r Biocpkg("SingleCellExperiment")` (SCE) class, allowing for the following easy-to-use workflow:

1. as the initial step of single-cell deconcolution, `assignPrelim` will return a SCE containing the input measurement data, barcoding scheme, and preliminary event assignments.
2. assignments will be made final by `applyCutoffs`. It is recommended to estimate, and possibly adjust, population-specific separation cutoffs by running `estCutoffs` prior to this.
3. `plotYields`, `plotEvents` and `plotMahal` aim to guide selection of devoncolution parameters and to give a sense of the resulting barcode assignment quality.

## Debarcoding workflow

### `assignPrelim`: Assignment of preliminary IDs

The debarcoding process commences by assigning each event a preliminary barcode ID. `assignPrelim` thereby takes either a binary barcoding scheme or a vector of numeric masses as input, and accordingly assigns each event the appropirate row name or mass as ID. FCS files are read into R with `read.FCS` of the `r Biocpkg("flowCore")` package, and are represented as an object of class `flowFrame`:

```{r}
data(sample_ff)
sample_ff
```

The debarcoding scheme should be a binary table with sample IDs as row and numeric barcode masses as column names:

```{r}
data(sample_key)
head(sample_key)
```

Provided with a `SingleCellExperiment` and a compatible barcoding scheme (barcode masses must occur as parameters in the supplied SCE), `assignPrelim` will add the following data to the input SCE:
- assay slot `"scaled"` containing normalized expression values where each population is scaled to the 95%-quantile of events assigend to the respective population.
- `colData` columns `"bc_id"` and `"delta"` containing barcode IDs and separations between lowest positive and highest negative intensity (on the normalized scale)
- `rowData` column `is_bc` specifying, for each channel, whether it has been specified as a barcode channel

```{r assignPrelim, messages = FALSE} 
sce <- fcs2sce(sample_ff)
(sce <- assignPrelim(sce, bc_key = sample_key, verbose = FALSE))
# view barcode channels
rownames(sce)[rowData(sce)$is_bc]
# view number of events assigned to each barcode population
table(sce$bc_id)
```

### `estCutoffs`: Estimation of separation cutoffs

As opposed to a single global cutoff, `estCutoffs` will estimate a sample-specific cutoff to deal with barcode population cell yields that decline in an asynchronous fashion. Thus, the choice of thresholds for the distance between negative and positive barcode populations can be *i) automated* and *ii) independent for each barcode*. Nevertheless, reviewing the yield plots (see below), checking and possibly refining separation cutoffs is advisable. 

For the estimation of cutoff parameters we consider yields upon debarcoding as a function of the applied cutoffs. Commonly, this function will be characterized by an initial weak decline, where doublets are excluded, and subsequent rapid decline in yields to zero. Inbetween, low numbers of counts with intermediate barcode separation give rise to a plateau. To facilitate robust estimation, we fit a linear and a three-parameter log-logistic function [@Finney] to the yields function with the `LL.3` function of the `r CRANpkg("drc")` R package [@drc] (Figure \@ref(fig:estCutoffs)). As an adequate cutoff estimate, we target a point that marks the end of the plateau regime and on-set of yield decline to appropriately balance confidence in barcode assignment and cell yield. 

The goodness of the linear fit relative to the log-logistic fit is weighed as follow: 
$$w = \frac{\text{RSS}_{log-logistic}}{\text{RSS}_{log-logistic}+\text{RSS}_{linear}}$$

The cutoffs for both functions are defined as:

$$c_{linear} = -\frac{\beta_0}{2\beta_1}$$
$$c_{log-logistic}=\underset{x}{\arg\min}\:\frac{\vert\:f'(x)\:\vert}{f(x)} > 0.1$$

The final cutoff estimate $c$ is defined as the weighted mean between these estimates:

$$c=(1-w)\cdot c_{log-logistic}+w\cdot c_{linear}$$

![(\#fig:estCutoffs) Description of the automatic cutoff estimation for each individual population. The bar graphs indicate the distribution of cells relative to the barcode distance and the dotted line corresponds to the yield upon debarcoding as a function of the applied separation cutoff. This curve is fitted with a linear regression (blue line) and a three parameter log-logistic function (red line). The cutoff estimate is defined as the mean of estimates derived from both fits, weighted with the goodness of the respective fit.](../inst/extdata/estCutoffs.png)

```{r estCutoffs}
# estimate separation cutoffs
sce <- estCutoffs(sce)
# view separation cutoff estimates
metadata(sce)$sep_cutoffs
```

### `plotYields`: Selecting barcode separation cutoffs

For each barcode, `plotYields` will show the distribution of barcode separations and yields upon debarcoding as a function of separation cutoffs. If available, the currently used separation cutoff as well as its resulting yield within the population is indicated in the plot's main title.

Option `which = 0` will render a summary plot of all barcodes. All yield functions should behave as described above: decline, stagnation, decline. Convergence to 0 yield at low cutoffs is a strong indicator that staining in this channel did not work, and excluding the channel entirely is sensible in this case. It is thus recommended to **always** view the all-barcodes yield plot to eliminate uninformative populations, since small populations may cause difficulties when computing spill estimates.

```{r eval = FALSE}
plotYields(sce, which = c(0, "C1"), plotly = FALSE)
```

```{r plotYields, echo = FALSE, fig.width = 7, fig.height = 3.5}
ps <- plotYields(sce, which = c(0, "C1"), plotly = FALSE); ps[[1]]; ps[[2]]
```

### `applyCutoffs`: Applying deconvolution parameters

Once preliminary assignments have been made, `applyCutoffs` will apply the deconvolution parameters: Outliers are filtered by a Mahalanobis distance threshold, which takes into account each population's covariance, and doublets are removed by excluding events from a population if the separation between their positive and negative signals fall below a separation cutoff. Current thresholds are held in the `sep_cutoffs` and `mhl_cutoff` slots of the SCE's `metadata`. By default, `applyCutoffs` will try to access the `metadata` `"sep_cutoffs"` slopt of the input SCE, requiring having run `estCutoffs` prior to this, or manually specifying a vector or separation cutoffs. Alternatively, a numeric vector of cutoff values or a single, global value may be supplied In either case, it is highly recommended to thoroughly review the yields plot (see above), as the choice of separation cutoffs will determine debarcoding quality and cell yield.

```{r applyCutoffs}
# use global / population-specific separation cutoff(s)
sce2 <- applyCutoffs(sce)
sce3 <- applyCutoffs(sce, sep_cutoffs = 0.35)

# compare yields before and after applying 
# global / population-specific cutoffs
c(specific = mean(sce2$bc_id != 0),
    global = mean(sce3$bc_id != 0))
# proceed with population-specific filtering
sce <- sce2
```

### `plotEvents`: Normalized intensities

Normalized intensities for a barcode can be viewed with `plotEvents`. Here, each event corresponds to the intensities plotted on a vertical line at a given point along the x-axis. Option `which = 0` will display unassigned events, and the number of events shown for a given sample may be varied via argument `n`. If `which = "all"`, the function will render an event plot for all IDs (including 0) with events assigned.

```{r eval = FALSE}
# event plots for unassigned events
# & barcode population D1
plotEvents(sce, which = c(0, "D1"), n = 25)
```

```{r plotEvents, echo = FALSE, fig.width = 6, fig.height = 3}
ps <- plotEvents(sce, which = c(0, "D1"), n = 25); ps[[1]]; ps[[2]]
```

### `plotMahal`: All barcode biaxial plot

Function `plotMahal` will plot all inter-barcode interactions for the population specified with argument `which`. Events are colored by their Mahalanobis distance. <span style="color:firebrick">*NOTE: For more than 7 barcodes (up to 128 samples) the function will render an error, as this visualization is infeasible and hardly informative. Using the default Mahalanobis cutoff value of 30 is recommended in such cases.*</span> 

```{r plotMahal, fig.width = 6, fig.height = 6.5} 
plotMahal(sce, which = "B3")
```

# Compensation

`r Biocpkg("CATALYST")` performs compensation via a two-step approach comprising: 

i. identification of single positive populations via single-cell debarcoding (SCD) of single-stained beads (or cells)
i. estimation of a spillover matrix (SM) from the populations identified, followed by compensation via multiplication of measurement intensities by its inverse, the compensation matrix (CM).

***Retrieval of real signal.*** As in conventional flow cytometry, we can model spillover linearly, with the channel stained for as predictor, and spill-effected channels as response. Thus, the intensity observed in a given channel $j$ are a linear combination of its real signal and contributions of other channels that spill into it. Let $s_{ij}$ denote the proportion of channel $j$ signal that is due to channel $i$, and $w_j$ the set of channels that spill into channel $j$. Then

$$I_{j, observed}\; = I_{j, real} + \sum_{i\in w_j}{s_{ij}}$$

In matrix notation, measurement intensities may be viewed as the convolution of real intensities and a spillover matrix with dimensions number of events times number of measurement parameters:

$$I_{observed}\; = I_{real} \cdot SM$$

Therefore, we can estimate the real signal, $I_{real}\;$, as:

$$I_{real} = I_{observed}\; \cdot {SM}^{-1} = I_{observed}\; \cdot CM$$ 
where $\text{SM}^{-1}$ is termed compensation matrix ($\text{CM}$). This approach is implemented in `compCytof(..., method = "flow")` and makes use of `r BiocStyle::Biocpkg("flowCore")`'s `compensate` function.

While mathematically exact, the solution to this equation will yield negative values, and does not account for the fact that real signal would be strictly non-negative counts. A computationally efficient way to adress this is the use of non-negative linear least squares (NNLS):

$$\min \: \{ \: ( I_{observed} - SM \cdot I_{real} ) ^ T \cdot ( I_{observed} - SM \cdot I_{real} ) \: \} \quad \text{s.t.} \: I_{real} â¥ 0$$

This approach will solve for $I_{real}$ such that the least squares criterion is optimized under the constraint of non-negativity. To arrive at such a solution we apply the Lawson-Hanson algorithm [@nnls1; @nnls2] for NNLS implemented in the  `r BiocStyle::Rpackage("nnls")` R package (`method="nnls"`).

***Estimation of SM.*** Because any signal not in a single stain experimentâs primary channel $j$ results from channel crosstalk, each spill entry $s_{ij}$ can be approximated by the slope of a linear regression with channel $j$ signal as the response, and channel $i$ signals as the predictors, where $i\in w_j$. `computeSpillmat()` offers two alternative ways for spillover estimation, summarized in Figure \@ref(fig:methods).

The `default` method approximates this slope with the following single-cell derived estimate: Let $i^+$ denote the set of cells that are possitive in channel $i$, and $s_{ij}^c$ be the channel $i$ to $j$ spill computed for a cell $c$ that has been assigned to this population. We approximate $s_{ij}^c$ as the ratio between the signal in unstained spillover receiving and stained spillover emitting channel, $I_j$ and $I_i$, respectively. The expected background in these channels, $m_j^-$ and $m_i^-$, is computed as the median signal of events that are i) negative in the channels for which spill is estimated ($i$ and $j$); ii) not assigned to potentionally interacting channels; and, iii) not unassigned, and subtracted from all measurements:

$$s_{ij}^c = \frac{I_j - m_j^{i-}}{I_i - m_i^{i-}}$$

Each entry $s_{ij}$ in $\text{SM}$ is then computed as the median spillover across all cells $c\in i^+$:

$$s_{ij} = \text{med}(s_{ij}^c\:|\:c\in i^+)$$

In a population-based fashion, as done in conventional flow cytometry, `method = "classic"` calculates $s_{ij}$ as the slope of a line through the medians (or trimmed means) of stained and unstained populations, $m_j^+$ and $m_i^+$, respectively. Background signal is computed as above and substracted, according to:

$$s_{ij} = \frac{m_j^+-m_j^-}{m_i^+-m_i^-}$$

![(\#fig:methods) Population versus single-cell based spillover estimation.](../inst/extdata/methods.png)

On the basis of their additive nature, spill values are estimated independently for every pair of interacting channels. `interactions = "default"` thereby exclusively takes into account interactions that are sensible from a chemical and physical point of view:

- $M\pm1$ channels (*abundance sensitivity*)
- the $M+16$ channel (*oxide formation*)
- channels measuring isotopes (*isotopic impurities*) 

See Table \@ref(tab:isotopes) for the list of mass channels considered to potentionally contain isotopic contaminatons, along with a heatmap representation of all interactions considered by the `default` method in Figure \@ref(fig:interactions).

Metal | Isotope masses                    |
----- | --------------------------------- |
La    | 138, 139                          |
Pr    | 141                               |
Nd    | 142, 143, 144, 145, 146, 148, 150 |
Sm    | 144, 147, 148, 149, 150, 152, 154 |
Eu    | 151, 153                          |
Gd    | 152, 154, 155, 156, 157, 158, 160 |
Dy    | 156, 158, 160, 161, 162, 163, 164 |
Er    | 162, 164, 166, 167, 168, 170      |
Tb    | 159                               |
Ho    | 165                               |
Yb    | 168, 170, 171, 172, 173, 174, 176 |
Tm    | 169                               |
Lu    | 175, 176                          |

: (\#tab:isotopes) List of isotopes available for each metal used in CyTOF. In addition to $M\pm1$ and $M+16$ channels, these mass channels are considered during estimation of spill to capture channel crosstalk that is due to isotopic contanimations [@isotopes].

![(\#fig:interactions) Heatmap of spill expected interactions. These are considered by the default method of <i>computeSpillmat</i>.](../inst/extdata/interactions.png){width="80%"}

Alternatively, `interactions = "all"` will compute a spill estimate for all $n\cdot(n-1)$ possible interactions, where $n$ denotes the number of measurement parameters. Estimates falling below the threshold specified by `th` will be set to zero. Lastly, note that diagonal entries $s_{ii} = 1$ for all $i\in 1, ..., n$, so that spill is relative to the total signal measured in a given channel.

## Compensation workflow

### `computeSpillmat`: Estimation of the spillover matrix

Given a SCE of single-stained beads (or cells) and a numeric vector specifying the masses stained for, `computeSpillmat` estimates the spillover matrix (SM) as described above; the estimated SM will be stored in the SCE's `metadata` under `"spillover_matrix"`. 

Spill values are affected my the `method` chosen for their estimation, that is `"median"` or `"mean"`, and, in the latter case, the specified `trim` percentage. The process of adjusting these options and reviewing the compensated data may iterative until compensation is satisfactory.

```{r computeSpillmat} 
# get single-stained control samples
data(ss_exp)

# specify mass channels stained for & debarcode
bc_ms <- c(139, 141:156, 158:176)
sce <- fcs2sce(ss_exp, by_time = FALSE)
sce <- assignPrelim(sce, bc_key = bc_ms, verbose = FALSE)
sce <- applyCutoffs(estCutoffs(sce))

# compute & extract spillover matrix
sce <- computeSpillmat(sce)
sm <- metadata(sce)$spillover_matrix

# do some sanity checks
ss_chs <- rownames(sce)[rowData(sce)$is_bc]
all(diag(sm[ss_chs, ss_chs]) == 1)
all(sm >= 0 & sm <= 1)
```

### `plotSpillmat`: Spillover matrix heatmap

`plotSpillmat` provides a visualization of estimated spill percentages as a heatmap. Channels without a single-antibody stained control are annotated in grey, and colours are ramped to the highest spillover value present. Option `annotate = TRUE` (the default) will display spill values inside each bin, and the total amount of spill caused and received by each channel on the top and to the right, respectively.

`plotSpillmat` will try and access the SM stored in the input SCE's `"spillover_matrix"` `metadata` slot, requiring having run `computeSpillmat` or manually specifying a matrix of appropriate format.

```{r plotSpillmat, fig.width = 6, fig.height = 6} 
plotSpillmat(sce, plotly = FALSE) 
```

### `compCytof`: Compensation of mass cytometry data

Assuming a linear spillover, `compCytof` compensates mass cytometry based experiments using a provided spillover matrix. If the spillover matrix (SM) does not contain the same set of columns as the input experiment, it will be adapted according to the following rules:

1. columns present in the SM but not in the input data will be removed from it
1. non-metal columns present in the input but not in the SM will be added such that they do neither receive nor cause spill
1. metal columns that have the same mass as a channel present in the SM will receive (but not emit) spillover according to that channel
1. if an added channel could potentially receive spillover (as it has +/-1M or +16M of, or is of the same metal type as another channel measured), a warning will be issued as there could be spillover interactions that have been missed and may lead to faulty compensation

If `out_path = NULL` (the default), the function will return a `SingleCellExperiment` containing both compensated counts (assay slot `"x_comped"`, where `x` is the specified assay data to be compensated) and, if `transform = TRUE`, expression values (assay slot `"exprs_comped"`). 

```{r compCytof, message = FALSE, fig.wide = TRUE}
# construct SCE of multiplexed cells
data(mp_cells)
sce <- fcs2sce(mp_cells, by_time = FALSE)
# compensate using `flowCore` & NNLS-method
sce <- compCytof(sce, sm, method = "flow")
sce <- compCytof(sce, sm, method = "nnls")
# visualize data before & after compensation
chs <- c("Er167Di", "Er168Di")
as <- grep("exprs", assayNames(sce), value = TRUE)
ps <- lapply(as, function(a) plotScatter(sce, chs, assay = a) + ggtitle(a))
plot_grid(plotlist = ps, nrow = 1, align = "v")
```

# Session information

```{r session-info}
sessionInfo()
```

# References